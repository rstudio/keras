<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>unet_linux • keras</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../jquery.sticky-kit.min.js"></script><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../../index.html">Keras for R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Getting Started</li>
    <li>
      <a href="../../articles/sequential_model.html">Guide to the Sequential Model</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Guide to the Functional API</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/keras">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>unet_linux</h1>
            
          </div>

    
    
<div class="contents">
<div class="source-ref">
<p><span class="caption">Source: </span><a href="https://github.com/rstudio/keras/blob/master/vignettes/examples/unet_linux.R" class="uri">https://github.com/rstudio/keras/blob/master/vignettes/examples/unet_linux.R</a></p>
</div>
<p>To run this example:</p>
<ol style="list-style-type: decimal">
<li><p>Download the train.zip and train_masks.zip files from: <a href="https://www.kaggle.com/c/carvana-image-masking-challenge/data" class="uri">https://www.kaggle.com/c/carvana-image-masking-challenge/data</a></p></li>
<li><p>Create an “input” directory and extract the zip files into it (after this there should be “train” and “train_masks” subdirectories within the “input” directory).</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#` This code runs only on Linux because of specific parallel backend. </span>
<span class="co">#` You can find Windows version here: https://keras.rstudio.com/articles/examples/unet.html</span>
<span class="co">#` unet architecture is based on original Python code </span>
<span class="co">#` from https://github.com/petrosgk/Kaggle-Carvana-Image-Masking-Challenge. </span>
<span class="co">#` It shows an example of creating custom architectures in R version of keras </span>
<span class="co">#` and working with images using magick package. </span>
<span class="co">#` parallel + doParallel + foreach allows to speed up the code.</span>
<span class="co">#` You can download the data from https://www.kaggle.com/c/carvana-image-masking-challenge</span>

<span class="kw">library</span>(keras)
<span class="kw">library</span>(magick)
<span class="kw">library</span>(abind)
<span class="kw">library</span>(reticulate)
<span class="kw">library</span>(doMC)
<span class="kw">library</span>(foreach)


<span class="co"># Parameters -----------------------------------------------------</span>

input_size &lt;-<span class="st"> </span><span class="dv">128</span>

epochs &lt;-<span class="st"> </span><span class="dv">30</span>
batch_size &lt;-<span class="st"> </span><span class="dv">16</span>

orig_width &lt;-<span class="st"> </span><span class="dv">1918</span>
orig_height &lt;-<span class="st"> </span><span class="dv">1280</span>

threshold &lt;-<span class="st"> </span><span class="fl">0.5</span>

train_samples &lt;-<span class="st"> </span><span class="dv">5088</span>
train_index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>train_samples, <span class="kw">round</span>(train_samples <span class="op">*</span><span class="st"> </span><span class="fl">0.8</span>)) <span class="co"># 80%</span>
val_index &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>train_samples)[<span class="op">-</span>train_index]

images_dir &lt;-<span class="st"> "./input/train/"</span> 
masks_dir &lt;-<span class="st"> "./input/train_masks/"</span>


<span class="co"># Loss function -----------------------------------------------------</span>

K &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/backend.html">backend</a></span>()

dice_coef &lt;-<span class="st"> </span><span class="cf">function</span>(y_true, y_pred, <span class="dt">smooth =</span> <span class="fl">1.0</span>) {
    y_true_f &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">flatten</span>(y_true)
    y_pred_f &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">flatten</span>(y_pred)
    intersection &lt;-<span class="st"> </span>K<span class="op">$</span><span class="kw">sum</span>(y_true_f <span class="op">*</span><span class="st"> </span>y_pred_f)
    result &lt;-<span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>intersection <span class="op">+</span><span class="st"> </span>smooth) <span class="op">/</span><span class="st"> </span>
<span class="st">        </span>(K<span class="op">$</span><span class="kw">sum</span>(y_true_f) <span class="op">+</span><span class="st"> </span>K<span class="op">$</span><span class="kw">sum</span>(y_pred_f) <span class="op">+</span><span class="st"> </span>smooth)
    <span class="kw">return</span>(result)
}

bce_dice_loss &lt;-<span class="st"> </span><span class="cf">function</span>(y_true, y_pred) {
    result &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/loss_mean_squared_error.html">loss_binary_crossentropy</a></span>(y_true, y_pred) <span class="op">+</span>
<span class="st">        </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">dice_coef</span>(y_true, y_pred))
    <span class="kw">return</span>(result)
}


<span class="co"># U-net 128 -----------------------------------------------------</span>

get_unet_<span class="dv">128</span> &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">128</span>, <span class="dv">128</span>, <span class="dv">3</span>),
                         <span class="dt">num_classes =</span> <span class="dv">1</span>) {
    
    inputs &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_input.html">layer_input</a></span>(<span class="dt">shape =</span> input_shape)
    <span class="co"># 128</span>
    
    down1 &lt;-<span class="st"> </span>inputs <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) 
    down1_pool &lt;-<span class="st"> </span>down1 <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">strides =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
    <span class="co"># 64</span>
    
    down2 &lt;-<span class="st"> </span>down1_pool <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">128</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">128</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) 
    down2_pool &lt;-<span class="st"> </span>down2 <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">strides =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
    <span class="co"># 32</span>
    
    down3 &lt;-<span class="st"> </span>down2_pool <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">256</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">256</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) 
    down3_pool &lt;-<span class="st"> </span>down3 <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">strides =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
    <span class="co"># 16</span>
    
    down4 &lt;-<span class="st"> </span>down3_pool <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">512</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">512</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) 
    down4_pool &lt;-<span class="st"> </span>down4 <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_max_pooling_2d.html">layer_max_pooling_2d</a></span>(<span class="dt">pool_size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="dt">strides =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
    <span class="co"># 8</span>
    
    center &lt;-<span class="st"> </span>down4_pool <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">1024</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">1024</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) 
    <span class="co"># center</span>
    
    up4 &lt;-<span class="st"> </span>center <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_upsampling_2d.html">layer_upsampling_2d</a></span>(<span class="dt">size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span>{<span class="kw"><a href="../../reference/layer_concatenate.html">layer_concatenate</a></span>(<span class="dt">inputs =</span> <span class="kw">list</span>(down4, .), <span class="dt">axis =</span> <span class="dv">3</span>)} <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">512</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">512</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">512</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>)
    <span class="co"># 16</span>
    
    up3 &lt;-<span class="st"> </span>up4 <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_upsampling_2d.html">layer_upsampling_2d</a></span>(<span class="dt">size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span>{<span class="kw"><a href="../../reference/layer_concatenate.html">layer_concatenate</a></span>(<span class="dt">inputs =</span> <span class="kw">list</span>(down3, .), <span class="dt">axis =</span> <span class="dv">3</span>)} <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">256</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">256</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">256</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>)
    <span class="co"># 32</span>
    
    up2 &lt;-<span class="st"> </span>up3 <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_upsampling_2d.html">layer_upsampling_2d</a></span>(<span class="dt">size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span>{<span class="kw"><a href="../../reference/layer_concatenate.html">layer_concatenate</a></span>(<span class="dt">inputs =</span> <span class="kw">list</span>(down2, .), <span class="dt">axis =</span> <span class="dv">3</span>)} <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">128</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">128</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">128</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>)
    <span class="co"># 64</span>
    
    up1 &lt;-<span class="st"> </span>up2 <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_upsampling_2d.html">layer_upsampling_2d</a></span>(<span class="dt">size =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span>{<span class="kw"><a href="../../reference/layer_concatenate.html">layer_concatenate</a></span>(<span class="dt">inputs =</span> <span class="kw">list</span>(down1, .), <span class="dt">axis =</span> <span class="dv">3</span>)} <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(<span class="dt">filters =</span> <span class="dv">64</span>, <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">3</span>), <span class="dt">padding =</span> <span class="st">"same"</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw"><a href="../../reference/layer_activation.html">layer_activation</a></span>(<span class="st">"relu"</span>)
    <span class="co"># 128</span>
    
    classify &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/layer_conv_2d.html">layer_conv_2d</a></span>(up1,
                              <span class="dt">filters =</span> num_classes, 
                              <span class="dt">kernel_size =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>),
                              <span class="dt">activation =</span> <span class="st">"sigmoid"</span>)
    
    
    model &lt;-<span class="st"> </span><span class="kw"><a href="../../reference/keras_model.html">keras_model</a></span>(
        <span class="dt">inputs =</span> inputs,
        <span class="dt">outputs =</span> classify
    )
    
    model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/compile.html">compile</a></span>(
        <span class="dt">optimizer =</span> <span class="kw"><a href="../../reference/optimizer_rmsprop.html">optimizer_rmsprop</a></span>(<span class="dt">lr =</span> <span class="fl">0.0001</span>),
        <span class="dt">loss =</span> bce_dice_loss,
        <span class="dt">metrics =</span> <span class="kw">c</span>(dice_coef)
    )
    
    <span class="kw">return</span>(model)
}

model &lt;-<span class="st"> </span><span class="kw">get_unet_128</span>()


<span class="co"># Read and augmentation functions -----------------------------------------------------</span>

imagesRead &lt;-<span class="st"> </span><span class="cf">function</span>(image_file,
                       mask_file,
                       <span class="dt">target_width =</span> <span class="dv">128</span>, 
                       <span class="dt">target_height =</span> <span class="dv">128</span>) {
    img &lt;-<span class="st"> </span><span class="kw">image_read</span>(image_file)
    img &lt;-<span class="st"> </span><span class="kw">image_scale</span>(img, <span class="kw">paste0</span>(target_width, <span class="st">"x"</span>, target_height, <span class="st">"!"</span>))
    
    mask &lt;-<span class="st"> </span><span class="kw">image_read</span>(mask_file)
    mask &lt;-<span class="st"> </span><span class="kw">image_scale</span>(mask, <span class="kw">paste0</span>(target_width, <span class="st">"x"</span>, target_height, <span class="st">"!"</span>))
    <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">img =</span> img, <span class="dt">mask =</span> mask))
}

randomBSH &lt;-<span class="st"> </span><span class="cf">function</span>(img,
                      <span class="dt">u =</span> <span class="dv">0</span>,
                      <span class="dt">brightness_shift_lim =</span> <span class="kw">c</span>(<span class="dv">90</span>, <span class="dv">110</span>), <span class="co"># percentage</span>
                      <span class="dt">saturation_shift_lim =</span> <span class="kw">c</span>(<span class="dv">95</span>, <span class="dv">105</span>), <span class="co"># of current value</span>
                      <span class="dt">hue_shift_lim =</span> <span class="kw">c</span>(<span class="dv">80</span>, <span class="dv">120</span>)) {
    
    <span class="cf">if</span> (<span class="kw">rnorm</span>(<span class="dv">1</span>) <span class="op">&lt;</span><span class="st"> </span>u) <span class="kw">return</span>(img)
    
    brightness_shift &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, 
                              brightness_shift_lim[<span class="dv">1</span>], 
                              brightness_shift_lim[<span class="dv">2</span>])
    saturation_shift &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, 
                              saturation_shift_lim[<span class="dv">1</span>], 
                              saturation_shift_lim[<span class="dv">2</span>])
    hue_shift &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1</span>, 
                       hue_shift_lim[<span class="dv">1</span>], 
                       hue_shift_lim[<span class="dv">2</span>])
    
    img &lt;-<span class="st"> </span><span class="kw">image_modulate</span>(img, 
                          <span class="dt">brightness =</span> brightness_shift, 
                          <span class="dt">saturation =</span>  saturation_shift, 
                          <span class="dt">hue =</span> hue_shift)
    img
}

img2arr &lt;-<span class="st"> </span><span class="cf">function</span>(image, 
                    <span class="dt">target_width =</span> <span class="dv">128</span>,
                    <span class="dt">target_height =</span> <span class="dv">128</span>) {
    result &lt;-<span class="st"> </span><span class="kw">aperm</span>(<span class="kw">as.numeric</span>(image[[<span class="dv">1</span>]])[, , <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>], <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>)) <span class="co"># transpose</span>
    <span class="kw"><a href="http://www.rdocumentation.org/packages/reticulate/topics/array_reshape">array_reshape</a></span>(result, &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, target_width, target_height, <span class="dv">3</span>))
}

mask2arr &lt;-<span class="st"> </span><span class="cf">function</span>(mask,
                     <span class="dt">target_width =</span> <span class="dv">128</span>,
                     <span class="dt">target_height =</span> <span class="dv">128</span>) {
    result &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">as.numeric</span>(mask[[<span class="dv">1</span>]])[, , <span class="dv">1</span>]) <span class="co"># transpose</span>
    <span class="kw"><a href="http://www.rdocumentation.org/packages/reticulate/topics/array_reshape">array_reshape</a></span>(result, &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, target_width, target_height, <span class="dv">1</span>))
}


<span class="co"># Iterators with parallel processing -----------------------------------------------------</span>

<span class="kw">registerDoMC</span>(<span class="dv">4</span>)

train_generator &lt;-<span class="st"> </span><span class="cf">function</span>(images_dir, 
                            samples_index,
                            masks_dir, 
                            batch_size) {
    images_iter &lt;-<span class="st"> </span><span class="kw">list.files</span>(images_dir, 
                              <span class="dt">pattern =</span> <span class="st">".jpg"</span>, 
                              <span class="dt">full.names =</span> <span class="ot">TRUE</span>)[samples_index] <span class="co"># for current epoch</span>
    images_all &lt;-<span class="st"> </span><span class="kw">list.files</span>(images_dir, 
                             <span class="dt">pattern =</span> <span class="st">".jpg"</span>,
                             <span class="dt">full.names =</span> <span class="ot">TRUE</span>)[samples_index]  <span class="co"># for next epoch</span>
    masks_iter &lt;-<span class="st"> </span><span class="kw">list.files</span>(masks_dir, 
                             <span class="dt">pattern =</span> <span class="st">".gif"</span>,
                             <span class="dt">full.names =</span> <span class="ot">TRUE</span>)[samples_index] <span class="co"># for current epoch</span>
    masks_all &lt;-<span class="st"> </span><span class="kw">list.files</span>(masks_dir, 
                            <span class="dt">pattern =</span> <span class="st">".gif"</span>,
                            <span class="dt">full.names =</span> <span class="ot">TRUE</span>)[samples_index] <span class="co"># for next epoch</span>
    
    <span class="cf">function</span>() {
        
        <span class="co"># start new epoch</span>
        <span class="cf">if</span> (<span class="kw">length</span>(images_iter) <span class="op">&lt;</span><span class="st"> </span>batch_size) {
            images_iter &lt;&lt;-<span class="st"> </span>images_all
            masks_iter &lt;&lt;-<span class="st"> </span>masks_all
        }
        
        batch_ind &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(images_iter), batch_size)
        
        batch_images_list &lt;-<span class="st"> </span>images_iter[batch_ind]
        images_iter &lt;&lt;-<span class="st"> </span>images_iter[<span class="op">-</span>batch_ind]
        batch_masks_list &lt;-<span class="st"> </span>masks_iter[batch_ind]
        masks_iter &lt;&lt;-<span class="st"> </span>masks_iter[<span class="op">-</span>batch_ind]
        
        
        x_y_batch &lt;-<span class="st"> </span><span class="kw">foreach</span>(<span class="dt">i =</span> <span class="dv">1</span><span class="op">:</span>batch_size) <span class="op">%dopar%</span><span class="st"> </span>{
            x_y_imgs &lt;-<span class="st"> </span><span class="kw">imagesRead</span>(<span class="dt">image_file =</span> batch_images_list[i],
                                   <span class="dt">mask_file =</span> batch_masks_list[i])
            <span class="co"># augmentation</span>
            x_y_imgs<span class="op">$</span>img &lt;-<span class="st"> </span><span class="kw">randomBSH</span>(x_y_imgs<span class="op">$</span>img)
            <span class="co"># return as arrays</span>
            x_y_arr &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">img2arr</span>(x_y_imgs<span class="op">$</span>img),
                            <span class="dt">y =</span> <span class="kw">mask2arr</span>(x_y_imgs<span class="op">$</span>mask))
        }
        
        x_y_batch &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/purrr/topics/transpose">transpose</a></span>(x_y_batch)
        
        x_batch &lt;-<span class="st"> </span><span class="kw">do.call</span>(abind, <span class="kw">c</span>(x_y_batch<span class="op">$</span>x, <span class="kw">list</span>(<span class="dt">along =</span> <span class="dv">1</span>)))
        
        y_batch &lt;-<span class="st"> </span><span class="kw">do.call</span>(abind, <span class="kw">c</span>(x_y_batch<span class="op">$</span>y, <span class="kw">list</span>(<span class="dt">along =</span> <span class="dv">1</span>)))
        
        result &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">to_numpy_array</span>(x_batch), 
                       <span class="kw">to_numpy_array</span>(y_batch))
        <span class="kw">return</span>(result)
    }
}

val_generator &lt;-<span class="st"> </span><span class="cf">function</span>(images_dir, 
                          samples_index,
                          masks_dir, 
                          batch_size) {
    images_iter &lt;-<span class="st"> </span><span class="kw">list.files</span>(images_dir, 
                              <span class="dt">pattern =</span> <span class="st">".jpg"</span>, 
                              <span class="dt">full.names =</span> <span class="ot">TRUE</span>)[samples_index] <span class="co"># for current epoch</span>
    images_all &lt;-<span class="st"> </span><span class="kw">list.files</span>(images_dir, 
                             <span class="dt">pattern =</span> <span class="st">".jpg"</span>,
                             <span class="dt">full.names =</span> <span class="ot">TRUE</span>)[samples_index]  <span class="co"># for next epoch</span>
    masks_iter &lt;-<span class="st"> </span><span class="kw">list.files</span>(masks_dir, 
                             <span class="dt">pattern =</span> <span class="st">".gif"</span>,
                             <span class="dt">full.names =</span> <span class="ot">TRUE</span>)[samples_index] <span class="co"># for current epoch</span>
    masks_all &lt;-<span class="st"> </span><span class="kw">list.files</span>(masks_dir, 
                            <span class="dt">pattern =</span> <span class="st">".gif"</span>,
                            <span class="dt">full.names =</span> <span class="ot">TRUE</span>)[samples_index] <span class="co"># for next epoch</span>
    
    <span class="cf">function</span>() {
        
        <span class="co"># start new epoch</span>
        <span class="cf">if</span> (<span class="kw">length</span>(images_iter) <span class="op">&lt;</span><span class="st"> </span>batch_size) {
            images_iter &lt;&lt;-<span class="st"> </span>images_all
            masks_iter &lt;&lt;-<span class="st"> </span>masks_all
        }
        
        batch_ind &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(images_iter), batch_size)
        
        batch_images_list &lt;-<span class="st"> </span>images_iter[batch_ind]
        images_iter &lt;&lt;-<span class="st"> </span>images_iter[<span class="op">-</span>batch_ind]
        batch_masks_list &lt;-<span class="st"> </span>masks_iter[batch_ind]
        masks_iter &lt;&lt;-<span class="st"> </span>masks_iter[<span class="op">-</span>batch_ind]
        
        
        x_y_batch &lt;-<span class="st"> </span><span class="kw">foreach</span>(<span class="dt">i =</span> <span class="dv">1</span><span class="op">:</span>batch_size) <span class="op">%dopar%</span><span class="st"> </span>{
            x_y_imgs &lt;-<span class="st"> </span><span class="kw">imagesRead</span>(<span class="dt">image_file =</span> batch_images_list[i],
                                   <span class="dt">mask_file =</span> batch_masks_list[i])
            <span class="co"># without augmentation</span>
            
            <span class="co"># return as arrays</span>
            x_y_arr &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">img2arr</span>(x_y_imgs<span class="op">$</span>img),
                            <span class="dt">y =</span> <span class="kw">mask2arr</span>(x_y_imgs<span class="op">$</span>mask))
        }
        
        x_y_batch &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/purrr/topics/transpose">transpose</a></span>(x_y_batch)
        
        x_batch &lt;-<span class="st"> </span><span class="kw">do.call</span>(abind, <span class="kw">c</span>(x_y_batch<span class="op">$</span>x, <span class="kw">list</span>(<span class="dt">along =</span> <span class="dv">1</span>)))
        
        y_batch &lt;-<span class="st"> </span><span class="kw">do.call</span>(abind, <span class="kw">c</span>(x_y_batch<span class="op">$</span>y, <span class="kw">list</span>(<span class="dt">along =</span> <span class="dv">1</span>)))
        
        result &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">to_numpy_array</span>(x_batch), 
                       <span class="kw">to_numpy_array</span>(y_batch))
        <span class="kw">return</span>(result)
    }
}

train_iterator &lt;-<span class="st"> </span><span class="kw">py_iterator</span>(<span class="kw">train_generator</span>(<span class="dt">images_dir =</span> images_dir,
                                              <span class="dt">masks_dir =</span> masks_dir,
                                              <span class="dt">samples_index =</span> train_index,
                                              <span class="dt">batch_size =</span> batch_size))

val_iterator &lt;-<span class="st"> </span><span class="kw">py_iterator</span>(<span class="kw">val_generator</span>(<span class="dt">images_dir =</span> images_dir,
                                          <span class="dt">masks_dir =</span> masks_dir,
                                          <span class="dt">samples_index =</span> val_index,
                                          <span class="dt">batch_size =</span> batch_size))


<span class="co"># Training -----------------------------------------------------</span>

<span class="kw"><a href="http://www.rdocumentation.org/packages/tensorflow/topics/tensorboard">tensorboard</a></span>(<span class="st">"logs_r"</span>)

callbacks_list &lt;-<span class="st"> </span><span class="kw">list</span>(
    <span class="kw"><a href="../../reference/callback_tensorboard.html">callback_tensorboard</a></span>(<span class="st">"logs_r"</span>),
    <span class="kw"><a href="../../reference/callback_early_stopping.html">callback_early_stopping</a></span>(<span class="dt">monitor =</span> <span class="st">"val_python_function"</span>,
                            <span class="dt">min_delta =</span> <span class="fl">1e-4</span>,
                            <span class="dt">patience =</span> <span class="dv">8</span>,
                            <span class="dt">verbose =</span> <span class="dv">1</span>,
                            <span class="dt">mode =</span> <span class="st">"max"</span>),
    <span class="kw"><a href="../../reference/callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau</a></span>(<span class="dt">monitor =</span> <span class="st">"val_python_function"</span>,
                                  <span class="dt">factor =</span> <span class="fl">0.1</span>,
                                  <span class="dt">patience =</span> <span class="dv">4</span>,
                                  <span class="dt">verbose =</span> <span class="dv">1</span>,
                                  <span class="dt">epsilon =</span> <span class="fl">1e-4</span>,
                                  <span class="dt">mode =</span> <span class="st">"max"</span>),
    <span class="kw"><a href="../../reference/callback_model_checkpoint.html">callback_model_checkpoint</a></span>(<span class="dt">filepath =</span> <span class="st">"weights_r/unet128_{epoch:02d}.h5"</span>,
                              <span class="dt">monitor =</span> <span class="st">"val_python_function"</span>,
                              <span class="dt">save_best_only =</span> <span class="ot">TRUE</span>,
                              <span class="dt">save_weights_only =</span> <span class="ot">TRUE</span>, 
                              <span class="dt">mode =</span> <span class="st">"max"</span> )
)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../../reference/fit_generator.html">fit_generator</a></span>(
    train_iterator,
    <span class="dt">steps_per_epoch =</span> <span class="kw">as.integer</span>(<span class="kw">length</span>(train_index) <span class="op">/</span><span class="st"> </span>batch_size), 
    <span class="dt">epochs =</span> epochs, 
    <span class="dt">validation_data =</span> val_iterator,
    <span class="dt">validation_steps =</span> <span class="kw">as.integer</span>(<span class="kw">length</span>(val_index) <span class="op">/</span><span class="st"> </span>batch_size),
    <span class="dt">verbose =</span> <span class="dv">1</span>,
    <span class="dt">callbacks =</span> callbacks_list
)</code></pre></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by JJ Allaire, François Chollet,  RStudio,  Google.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
